{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c8a538f",
   "metadata": {},
   "source": [
    "\n",
    "# üìò FB3PFB ‚Äî NHANES (Intro notebook)\n",
    "\n",
    "**Goal:** a very simple, step-by-step analysis in Google Colab, with no installations or Drive.  \n",
    "What we‚Äôll do:\n",
    "- Load minimal libraries.\n",
    "- Download **DEMO_J**, **HDL_J**, **TRIGLY_J** directly from the CDC site.\n",
    "- Recode `riagendr` ‚Üí `sex` (Male/Female).\n",
    "- Convert HDL, triglycerides from **mg/dL** ‚Üí **mmol/L**.\n",
    "- Show mean/SD/median/IQR for **age** by **sex**.\n",
    "- Draw a **density plot** of HDL by sex.\n",
    "- Compute **difference in HDL** (Female ‚àí Male) and a **t-test**.\n",
    "- Make a **scatter plot** of HDL vs Age.\n",
    "- Fit a tiny **OLS regression**: HDL ~ sex + age.\n",
    "\n",
    "> This notebook is intentionally simple (no custom functions unless necessary).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe19c4cf",
   "metadata": {},
   "source": [
    "## 1) Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730d4fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Core libraries ===========================================================\n",
    "import sys                  # lets us inspect the runtime (e.g., detect Colab vs local)\n",
    "from pathlib import Path    # safer, cleaner file paths than using raw strings\n",
    "\n",
    "import pandas as pd         # tables/data frames, reading XPT/CSV, cleaning, groupby, etc.\n",
    "import numpy as np          # basic numerical helpers (arrays, NaNs); pandas uses it under the hood\n",
    "\n",
    "# === Downloading files from the web (CDC) =====================================\n",
    "import requests             # simple HTTP library to fetch files from URLs\n",
    "\n",
    "# === Plotting =================================================================\n",
    "import matplotlib.pyplot as plt  # basic plotting (histograms, scatter, density via pandas)\n",
    "\n",
    "# === Statistics ================================================================\n",
    "from scipy import stats          # t-tests and other classic stats tests\n",
    "import statsmodels.formula.api as smf  # regression with R-style formulas (e.g., y ~ x1 + x2)\n",
    "\n",
    "# Show versions & environment\n",
    "print(f\"Python: {sys.version.split()[0]}\")\n",
    "print(f\"pandas: {pd.__version__} | numpy: {np.__version__}\")\n",
    "try:\n",
    "    import scipy, statsmodels\n",
    "    print(f\"scipy: {scipy.__version__} | statsmodels: {statsmodels.__version__}\")\n",
    "except Exception:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e03a34",
   "metadata": {},
   "source": [
    "## 2) Download DEMO, HDL, TRIGLY from CDC\n",
    "\n",
    "We save to `/content/data/raw` (Colab's temporary filesystem) when using Colab - otherwise locally.  \n",
    "We use a small dictionary (key = filename, value = URL) and loop over it to download each file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb46755",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== Paths + Download (works in BOTH Colab and local Jupyter) =================\n",
    "# This cell:\n",
    "#   1) Detects whether we are running in Google Colab or on your own computer.\n",
    "#   2) Chooses a safe place for data:\n",
    "#        - In Colab: /content/data/raw   (a temporary folder inside the VM)\n",
    "#        - Locally:  <your-repo>/data/raw  (at the REPOSITORY ROOT, not notebooks/)\n",
    "#   3) Creates data folders if they don't exist.\n",
    "#   4) Downloads three NHANES XPORT files (DEMO_J, HDL_J, TRIGLY_J) from CDC\n",
    "#      if they are not already present.\n",
    "#   5) Prints a small directory listing so you can SEE what was downloaded.\n",
    "#\n",
    "\n",
    "\n",
    "# --- STEP 1: Are we running in Google Colab? ----------------------------------\n",
    "# When you run in Colab, the special module \"google.colab\" is available.\n",
    "# We use that fact to decide which folders to use later on.\n",
    "IN_COLAB = \"google.colab\" in sys.modules\n",
    "print(\"Running in Colab?\", IN_COLAB)\n",
    "\n",
    "# --- STEP 2: Find a good project \"ROOT\" folder --------------------------------\n",
    "# ‚Ä¢ In Colab we keep things under /content (this is the writable VM workspace).\n",
    "# ‚Ä¢ Locally we want the repository ROOT (not the notebooks/ subfolder).\n",
    "#   To find the repo root, we walk UP the directory tree until we see a \".git\" folder.\n",
    "def find_repo_root(start: Path) -> Path:\n",
    "    \"\"\"\n",
    "    Walk upwards from 'start' until we find a '.git' folder (the repo root).\n",
    "    If we can't find one within ~10 levels, just return 'start' as a fallback.\n",
    "    \"\"\"\n",
    "    p = start.resolve()  # resolve = make absolute and clean up any \"..\"\n",
    "    for _ in range(10):  # try up to 10 parent directories\n",
    "        if (p / \".git\").exists():   # does this folder contain a .git directory?\n",
    "            return p                # yes ‚Üí this is the repo root\n",
    "        if p.parent == p:           # we've reached the filesystem root (\"/\")\n",
    "            break\n",
    "        p = p.parent                # go up one level and try again\n",
    "    return start.resolve()          # fallback if no .git was found\n",
    "\n",
    "if IN_COLAB:\n",
    "    ROOT = Path(\"/content\")         # Colab‚Äôs working area\n",
    "else:\n",
    "    ROOT = find_repo_root(Path.cwd())  # current working dir ‚Üí repo root\n",
    "\n",
    "print(\"ROOT folder:\", ROOT)\n",
    "\n",
    "# --- STEP 3: Define data folders and make sure they exist ---------------------\n",
    "# We keep raw downloads in data/raw and any processed outputs in data/processed.\n",
    "\n",
    "DATA_DIR = ROOT / \"data\" / \"raw\"\n",
    "PROC_DIR = ROOT / \"data\" / \"processed\"\n",
    "\n",
    "# Create the folders if they don't exist.\n",
    "# parents=True means: also create any missing parent folders.\n",
    "# exist_ok=True means: don't crash if the folder already exists.\n",
    "DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "PROC_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"DATA_DIR :\", DATA_DIR)\n",
    "print(\"PROC_DIR :\", PROC_DIR)\n",
    "\n",
    "# --- STEP 4: Download NHANES XPT files from CDC if missing --------------------\n",
    "# We keep a small dictionary (a ‚Äúdict‚Äù = key‚Üívalue map):\n",
    "#   key   = filename we want to save as\n",
    "#   value = the URL to download from\n",
    "FILES = {\n",
    "    \"DEMO_J.xpt\":   \"https://wwwn.cdc.gov/Nchs/Data/Nhanes/Public/2017/DataFiles/DEMO_J.xpt\",\n",
    "    \"HDL_J.xpt\":    \"https://wwwn.cdc.gov/Nchs/Data/Nhanes/Public/2017/DataFiles/HDL_J.XPT\",\n",
    "    \"TRIGLY_J.xpt\": \"https://wwwn.cdc.gov/Nchs/Data/Nhanes/Public/2017/DataFiles/TRIGLY_J.XPT\",\n",
    "}\n",
    "\n",
    "# Loop through the dict. In Python, \"for name, url in FILES.items()\" means:\n",
    "# take each (key, value) pair from the dict as (name, url).\n",
    "for fname, url in FILES.items():\n",
    "    dest = DATA_DIR / fname                 # full path to where the file should live\n",
    "    if dest.exists():\n",
    "        # If we already have the file, don‚Äôt download again (saves time/bandwidth).\n",
    "        print(f\"Already have {fname}\")\n",
    "        continue\n",
    "\n",
    "    print(f\"Downloading {fname} ‚Ä¶\")\n",
    "    # requests.get(...) fetches the file from the web.\n",
    "    # timeout=60 ‚Üí give up if there's no response for 60 seconds (avoids hanging forever).\n",
    "    r = requests.get(url, timeout=60)\n",
    "    r.raise_for_status()                    # if the server responded with an error, raise now\n",
    "    dest.write_bytes(r.content)             # write the downloaded bytes to disk\n",
    "\n",
    "# --- STEP 5: Show a simple directory listing of what we have ------------------\n",
    "print(\"\\nFiles found in DATA_DIR:\")\n",
    "for p in sorted(DATA_DIR.iterdir()):        # iterdir() lists children; sorted(...) makes it alphabetical\n",
    "    print(\" -\", p.name)\n",
    "\n",
    "# At this point:\n",
    "# ‚Ä¢ Your three .xpt files should exist in DATA_DIR.\n",
    "# ‚Ä¢ The rest of the notebook can refer to DATA_DIR to load them with pandas.\n",
    "#   Example:\n",
    "#       import pandas as pd\n",
    "#       df_demo = pd.read_sas(DATA_DIR / \"DEMO_J.xpt\", format=\"xport\", encoding=\"utf-8\")\n",
    "#       df_demo.columns = [c.lower() for c in df_demo.columns]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c874870",
   "metadata": {},
   "source": [
    "## 3) Load the three files into DataFrames\n",
    "\n",
    "We read **XPT** files with `pandas.read_sas(..., format=\"xport\")` and lower-case the columns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871dacde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Straight loading (no helpers)\n",
    "p_demo   = DATA_DIR / \"DEMO_J.xpt\"\n",
    "p_hdl    = DATA_DIR / \"HDL_J.xpt\"\n",
    "p_trigly = DATA_DIR / \"TRIGLY_J.xpt\"\n",
    "\n",
    "df_demo = pd.read_sas(p_demo, format=\"xport\", encoding=\"utf-8\")\n",
    "df_hdl  = pd.read_sas(p_hdl,  format=\"xport\", encoding=\"utf-8\")\n",
    "df_trig = pd.read_sas(p_trigly, format=\"xport\", encoding=\"utf-8\")\n",
    "\n",
    "# Lowercase all columns\n",
    "df_demo.columns = [c.lower() for c in df_demo.columns]\n",
    "df_hdl.columns  = [c.lower() for c in df_hdl.columns]\n",
    "df_trig.columns = [c.lower() for c in df_trig.columns]\n",
    "\n",
    "print(\"Shapes:\", df_demo.shape, df_hdl.shape, df_trig.shape)\n",
    "df_demo.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba40e29e",
   "metadata": {},
   "source": [
    "## 4) Minimal merges (left-join labs onto demographics by `seqn`)\n",
    "\n",
    "NHANES uses `SEQN` (lowercased here to `seqn`) as the participant ID.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9888c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep essentials from DEMO to stay tidy\n",
    "demo_keep = [\"seqn\", \"riagendr\", \"ridageyr\"]\n",
    "d = df_demo[demo_keep].copy()\n",
    "\n",
    "# Left-join HDL and triglycerides (drop_duplicates just in case)\n",
    "d = d.merge(df_hdl.drop_duplicates(subset=[\"seqn\"]), on=\"seqn\", how=\"left\")\n",
    "d = d.merge(df_trig.drop_duplicates(subset=[\"seqn\"]), on=\"seqn\", how=\"left\")\n",
    "\n",
    "# Peek at likely HDL/TG column names (NHANES names vary a bit by file)\n",
    "print([c for c in d.columns if \"hdl\" in c.lower()][:10])\n",
    "print([c for c in d.columns if \"trig\" in c.lower()][:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2885d58d",
   "metadata": {},
   "source": [
    "## 5) Recode sex; convert HDL & triglycerides to SI units\n",
    "\n",
    "- `riagendr`: **1 ‚Üí Male**, **2 ‚Üí Female**  \n",
    "- HDL: **mg/dL ‚Üí mmol/L** multiply by **0.02586**  \n",
    "- Triglycerides: **mg/dL ‚Üí mmol/L** multiply by **0.01129**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ae50a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recode sex\n",
    "d[\"riagendr\"] = pd.to_numeric(d[\"riagendr\"], errors=\"coerce\")\n",
    "d[\"sex\"] = d[\"riagendr\"].map({1: \"Male\", 2: \"Female\"})\n",
    "\n",
    "# Identify HDL & triglyceride columns\n",
    "hdl_col_candidates  = [c for c in d.columns if \"hdl\"  in c.lower()]\n",
    "trig_col_candidates = [c for c in d.columns if \"trig\" in c.lower()]\n",
    "\n",
    "print(\"HDL candidates:\", hdl_col_candidates[:5])\n",
    "print(\"Triglyceride candidates:\", trig_col_candidates[:5])\n",
    "\n",
    "# Pick specific columns (edit if needed)\n",
    "hdl_mgdl_col  = \"lbdhdd\" if \"lbdhdd\" in d.columns else hdl_col_candidates[0]\n",
    "trig_mgdl_col = \"lbxtr\"  if \"lbxtr\"  in d.columns else trig_col_candidates[0]\n",
    "\n",
    "# Ensure numeric\n",
    "d[hdl_mgdl_col]  = pd.to_numeric(d[hdl_mgdl_col],  errors=\"coerce\")\n",
    "d[trig_mgdl_col] = pd.to_numeric(d[trig_mgdl_col], errors=\"coerce\")\n",
    "d[\"ridageyr\"]    = pd.to_numeric(d[\"ridageyr\"],    errors=\"coerce\")\n",
    "\n",
    "# Create SI-unit columns\n",
    "d[\"hdl_mmol_l\"]  = d[hdl_mgdl_col]  * 0.02586\n",
    "d[\"tg_mmol_l\"]   = d[trig_mgdl_col] * 0.01129\n",
    "\n",
    "d[[\"sex\", \"ridageyr\", hdl_mgdl_col, \"hdl_mmol_l\", trig_mgdl_col, \"tg_mmol_l\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "017d0c86",
   "metadata": {},
   "source": [
    "## 6) Show mean/SD/median/IQR for **age**, by **sex**\n",
    "\n",
    "We loop over the two sex groups and print simple summaries.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eee6bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Age summary by sex ===\")\n",
    "for grp in [\"Male\", \"Female\"]:\n",
    "    sub = d.loc[d[\"sex\"] == grp, \"ridageyr\"].dropna()\n",
    "    if sub.empty:\n",
    "        print(f\"\\n{grp}: no data\")\n",
    "        continue\n",
    "\n",
    "    n = sub.size\n",
    "    mean = sub.mean()\n",
    "    sd   = sub.std(ddof=1)\n",
    "    median = sub.median()\n",
    "    q25 = sub.quantile(0.25)\n",
    "    q75 = sub.quantile(0.75)\n",
    "\n",
    "    print(f\"\\n{grp}: n={n}\")\n",
    "    print(f\"  Mean ¬± SD:    {mean:.1f} ¬± {sd:.1f}\")\n",
    "    print(f\"  Median [IQR]: {median:.1f} [{q25:.1f}, {q75:.1f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d9ceb4",
   "metadata": {},
   "source": [
    "## 7) Density plot (HDL in mmol/L by sex)\n",
    "\n",
    "Two kernel density curves, one per sex.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6507bd49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare series (drop missing)\n",
    "hdl_f = d.loc[d[\"sex\"] == \"Female\", \"hdl_mmol_l\"].dropna()\n",
    "hdl_m = d.loc[d[\"sex\"] == \"Male\",   \"hdl_mmol_l\"].dropna()\n",
    "\n",
    "plt.figure()\n",
    "hdl_f.plot(kind=\"kde\", linewidth=2, label=\"Female\")\n",
    "hdl_m.plot(kind=\"kde\", linewidth=2, label=\"Male\")\n",
    "plt.xlabel(\"HDL (mmol/L)\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.title(\"HDL distribution by sex\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "395df10a",
   "metadata": {},
   "source": [
    "## 8) Difference in HDL (Female ‚àí Male)\n",
    "\n",
    "Simple unweighted mean difference in mmol/L.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3c6483",
   "metadata": {},
   "outputs": [],
   "source": [
    "hdl_mean_f = hdl_f.mean()\n",
    "hdl_mean_m = hdl_m.mean()\n",
    "diff = hdl_mean_f - hdl_mean_m\n",
    "\n",
    "print(f\"Mean HDL (mmol/L): Female={hdl_mean_f:.2f}, Male={hdl_mean_m:.2f}\")\n",
    "print(f\"Difference (Female ‚àí Male): {diff:.2f} mmol/L\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a54d476",
   "metadata": {},
   "source": [
    "## 9) t-test (Welch‚Äôs, safer default)\n",
    "\n",
    "Welch‚Äôs t-test does not assume equal variances.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a85116e",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_stat, p_val = stats.ttest_ind(hdl_f, hdl_m, equal_var=False, nan_policy=\"omit\")\n",
    "print(\"Welch's t-test on HDL (mmol/L): Female vs Male\")\n",
    "print(f\"  t = {t_stat:.3f}, p = {p_val:.3g}\")\n",
    "print(f\"  n_female = {hdl_f.size}, n_male = {hdl_m.size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de5c5ba2",
   "metadata": {},
   "source": [
    "## 10) Scatter plot: HDL (mmol/L) vs Age (years)\n",
    "\n",
    "Points colored by sex.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f3af03",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "for label, sub in d.dropna(subset=[\"ridageyr\", \"hdl_mmol_l\"]).groupby(\"sex\", dropna=False):\n",
    "    plt.scatter(sub[\"ridageyr\"], sub[\"hdl_mmol_l\"], s=10, alpha=0.4, label=str(label))\n",
    "plt.xlabel(\"Age (years)\")\n",
    "plt.ylabel(\"HDL (mmol/L)\")\n",
    "plt.title(\"HDL vs Age by sex\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7047daf",
   "metadata": {},
   "source": [
    "## 11) Regression: HDL (mmol/L) ~ sex + age\n",
    "\n",
    "We treat `sex` as categorical using `C(sex)` and drop rows with missing values in model variables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393468a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = d[[\"hdl_mmol_l\", \"sex\", \"ridageyr\"]].dropna().copy()\n",
    "model = smf.ols(\"hdl_mmol_l ~ C(sex) + ridageyr\", data=reg).fit()\n",
    "print(model.summary())"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
