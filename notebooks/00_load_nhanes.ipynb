{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c0f4304",
   "metadata": {},
   "source": [
    "# 00 — Load NHANES data (starter notebook)\n",
    "\n",
    "This notebook demonstrates how to load a single NHANES file (either **XPT** or **CSV**) into pandas, do a few quick sanity checks, and save a lightweight copy for downstream analysis.\n",
    "\n",
    "**How to use**\n",
    "1. Put your raw NHANES file in `data/raw/` (e.g., `data/raw/DEMO_G.XPT`).\n",
    "2. Set `DATA_FILE` below to the filename you want to load.\n",
    "3. Run the cells.\n",
    "4. A feather/parquet copy will be written to `data/processed/`.\n",
    "\n",
    "> Works offline. Internet not required. No extra packages needed for `.XPT` (pandas can read XPT via `read_sas(..., format=\"xport\")`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd66c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Imports & display options\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 100)\n",
    "pd.set_option(\"display.width\", 120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc32df7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Project paths\n",
    "# Adjust if your repository uses different names\n",
    "ROOT = Path.cwd().resolve()\n",
    "DATA_RAW = ROOT / \"data\" / \"raw\"\n",
    "DATA_PROCESSED = ROOT / \"data\" / \"processed\"\n",
    "DATA_PROCESSED.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "ROOT, DATA_RAW, DATA_PROCESSED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deccd711",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Pick the file you want to load\n",
    "# Example: 'DEMO_G.XPT' (Demographics), or 'example.csv'\n",
    "DATA_FILE = \"DEMO_G.XPT\"  # <-- change me\n",
    "\n",
    "raw_path = (DATA_RAW / DATA_FILE).resolve()\n",
    "assert raw_path.exists(), f\"File not found: {raw_path} — place it in data/raw/ and try again.\"\n",
    "raw_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513112cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Helper: load either XPT or CSV based on extension\n",
    "def load_nhanes(path: Path) -> pd.DataFrame:\n",
    "    ext = path.suffix.lower()\n",
    "    if ext == \".xpt\":\n",
    "        # NHANES publishes SAS XPORT (.XPT). pandas can read it with read_sas(format=\"xport\").\n",
    "        df = pd.read_sas(path, format=\"xport\", encoding=\"utf-8\")\n",
    "    elif ext == \".csv\":\n",
    "        df = pd.read_csv(path)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported file extension: {ext}. Use .XPT or .CSV\")\n",
    "    # standardise column names: lowercase\n",
    "    df.columns = [c.lower() for c in df.columns]\n",
    "    return df\n",
    "\n",
    "df = load_nhanes(raw_path)\n",
    "df.shape, list(df.columns)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6884c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Quick look\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1dc5f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Basic info & missingness summary\n",
    "display(df.info())\n",
    "missing_summary = df.isna().mean().sort_values(ascending=False)\n",
    "missing_summary.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbaf5488",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Optional: select a few useful columns (example)\n",
    "# Update the list below to match your analysis needs.\n",
    "example_cols = [c for c in df.columns if c.startswith((\"seqn\",\"riagendr\",\"ridageyr\",\"ridreth\"))]\n",
    "df_small = df[example_cols].copy() if example_cols else df.copy()\n",
    "df_small.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8f0199",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Save lightweight copies for faster reloads\n",
    "feather_path = DATA_PROCESSED / (raw_path.stem.lower() + \".feather\")\n",
    "parquet_path = DATA_PROCESSED / (raw_path.stem.lower() + \".parquet\")\n",
    "\n",
    "df_small.reset_index(drop=True).to_feather(feather_path)\n",
    "df_small.reset_index(drop=True).to_parquet(parquet_path)\n",
    "\n",
    "feather_path, parquet_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4539f9",
   "metadata": {},
   "source": [
    "## Next steps\n",
    "- Repeat with other NHANES files (copy this notebook or parameterise `DATA_FILE`).\n",
    "- Join/merge on the participant ID (`SEQN` → usually lowercased to `seqn` above).\n",
    "- Add a small data dictionary (codebook) for selected variables in `docs/`.\n",
    "- Consider using **Jupytext** to keep a `.py` pair for clean diffs in Git.\n",
    "- When ready, promote any repeatable logic into `src/fb3pfb_nhanes/loader.py` and write tests in `tests/`.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
